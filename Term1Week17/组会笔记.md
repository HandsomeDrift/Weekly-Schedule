# 组会笔记

## RTMO

### YOLO

**YOLO**（You Only Look Once）架构是一种**实时目标检测模型**，最初由 Joseph Redmon 等人在 2016 年提出。它以速度和精度之间的良好平衡而闻名，被广泛应用于计算机视觉中的目标检测任务，例如物体识别、物体定位以及场景理解。

#### **YOLO架构的核心思想**

YOLO 架构的核心思想是将目标检测任务作为一个**单阶段问题**来解决，而不是将其分为多个步骤（例如区域提取和分类）。具体来说，YOLO一次性地对整个图像进行检测和分类，因而得名 "You Only Look Once"。

#### **YOLO架构的主要特点**

1. **单阶段检测：**
   - 将整个图像划分为一个固定大小的网格，每个网格单元负责预测其覆盖区域内目标的类别和位置（即目标的边界框）。
   - 不需要额外的区域提取阶段（如两阶段方法 Faster R-CNN 的候选区域生成）。
2. **高效：**
   - YOLO 使用单个神经网络直接预测目标的类别和边界框位置，这使得它非常高效，适合实时应用场景。
   - 计算效率高，能够在普通硬件上实现高帧率。
3. **全局推理：**
   - YOLO 在检测目标时对整个图像进行全局推理，而不是关注局部区域，因此对背景信息和目标之间的关系建模更好。
4. **端到端训练：**
   - YOLO 的目标检测任务可以通过一个统一的损失函数进行端到端训练，包括分类损失、定位损失和边界框置信度损失。

#### **YOLO的工作原理**

1. **输入图像处理：**
   - 将输入图像调整为固定大小，例如 416×416416 \times 416 像素。
2. **特征提取：**
   - 使用卷积神经网络（CNN）提取图像特征。
3. **网格划分：**
   - 将图像划分为 S×SS \times S 的网格，每个网格负责预测它覆盖区域的目标。
4. **边界框预测：**
   - 每个网格单元预测 BB 个边界框及其置信度分数，表示检测到目标的概率及边界框的准确性。
5. **类别预测：**
   - 每个网格还预测 CC 个类别概率分布，用于指示检测目标的类别。
6. **后处理：**
   - 应用非极大值抑制（NMS）算法去除多余的边界框，提高检测结果的准确性。

#### **在RTMO中的应用**

在 RTMO 中，YOLO 的架构被扩展和调整，用于多人姿态估计任务：

- **双一维热图预测（dual 1-D heatmaps）：** 用于表示关键点坐标。
- **动态坐标分类器（DCC）：** 进一步优化了 YOLO 在姿态估计中的精度和效率。

YOLO 的高速特性和端到端训练框架使其成为实时多人姿态估计的理想基础架构。

## CPN

### Stacked Hourglass Network（堆叠沙漏网络）

该方法通过堆叠多个沙漏形状的模块，逐步提取图像的多尺度特征并优化关键点预测

#### **网络结构**

**Stacked Hourglass Network** 的基本结构包括以下部分：

1. **沙漏模块（Hourglass Module）**：

   - 每个沙漏模块包含一个对称的下采样和上采样过程：

     - 下采样（Down-sampling）

       ：

       - 使用多层卷积和最大池化操作逐步减少特征图的空间分辨率，同时增加感受野。
       - 特征图经过若干层后，提取出全局上下文信息。

     - 上采样（Up-sampling）

       ：

       - 使用反卷积或插值操作逐步恢复特征图的空间分辨率，同时结合浅层的细节信息。
       - 在每次上采样时，结合来自对应下采样层的跳跃连接（Skip Connection），从而融合多尺度信息。

2. **堆叠多个沙漏模块**：

   - 网络通过堆叠多个沙漏模块，形成一个深层结构，每个模块输出的关键点预测作为下一模块的输入。
   - 这种堆叠机制能够逐步细化关键点的预测，提升最终的定位精度。

3. **中间监督（Intermediate Supervision）**：

   - 在每个沙漏模块的输出处添加监督信号（如热力图损失），以指导每个模块学习更好的特征表示。
   - 这种中间监督可以帮助网络更快地收敛，同时避免梯度消失问题。

4. **关键点热力图（Heatmap）**：

   - 每个沙漏模块的最终输出是一个关键点热力图，表示每个关键点在图像中可能出现的概率分布。
   - 热力图的峰值位置即为关键点的预测坐标。

#### **局限性**

1. **计算复杂度高**：
   - 堆叠多个沙漏模块会显著增加计算量和内存开销，不适用于实时场景。
2. **对遮挡的鲁棒性有限**：
   - 虽然结合了全局上下文，但在存在严重遮挡的情况下，预测精度可能会下降。
3. **固定结构**：
   - 模块堆叠的层数和设计较为固定，可能无法适应特定任务需求。

### **U-shape Structure**（U型结构）

#### **U-shape Structure 的基本组成**

U型结构通常包括以下几个部分：

1. **下采样路径（Encoder Path）**：
   - 用于逐步减少特征图的分辨率，同时提取语义信息。
   - 通常包含卷积操作、非线性激活函数（如 ReLU）、池化操作（如最大池化）等。
   - 每经过一个下采样阶段，特征图的分辨率降低，但通道数（特征数量）增加。
2. **上采样路径（Decoder Path）**：
   - 用于逐步恢复特征图的分辨率，同时结合下采样路径中提取的细节信息。
   - 通常包含反卷积（Transposed Convolution）或插值上采样操作，逐渐恢复特征图的空间分辨率。
   - 每个上采样阶段通常与下采样路径中的对应层通过跳跃连接（Skip Connection）进行特征融合。
3. **跳跃连接（Skip Connection）**：
   - 将下采样路径中对应分辨率的特征图直接传递到上采样路径，帮助上采样过程保留低层细节信息。
   - 通常通过逐像素加法或特征拼接（Concatenation）来融合来自编码器和解码器的特征。

### $1 \times 1$卷积

#### **$1 \times 1$ 卷积的作用**

**通道数的调整（Channel Reduction/Expansion）**：

- **作用**：通过 $1 \times 1$ 卷积可以改变特征图的通道数，而不会影响空间分辨率。
- **原理**：$1 \times 1$ 卷积核仅作用于输入特征图的通道维度，并对每个像素点的通道信息进行线性组合。
- 用途：
  - 减少特征图的通道数，从而降低计算复杂度（例如，在 GoogleNet 的 Inception 模块中）。
  - 增加通道数以增强特征表达能力（例如在深层网络中）。

### **RefineNet 的工作流程**

假设输入图像的大小为 $512 \times 512$：

1. **特征提取**：
   - 使用 ResNet 提取不同层次的特征（例如 $C2$, $C3$, $C4$, $C5$）。
   - 特征分辨率从高到低，语义信息从弱到强。
2. **特征细化**：
   - 将深层特征（低分辨率，强语义）==通过上采样恢复到更高分辨率==。
   - ==与对应浅层特征进行融合==，结合语义和细节信息。
3. **逐步细化**：
   - 多层 RefineNet 模块串联，逐层细化特征。
   - 最终生成高分辨率的分割预测。
4. **分割结果**：
   - 输出与原图分辨率一致的分割图，每个像素点对应一个类别标签。
