# RTMO

## 摘要

实时多人姿态估计在平衡速度与精度方面面临显著挑战。虽然两阶段的顶部-底部（top-down）方法随着图像中人物数量的增加会变慢，但现有的单阶段方法往往无法同时实现高精度和实时性能。本文提出了一种名为 **RTMO** 的单阶段姿态估计框架，通过在 YOLO 架构中使用双一维热图（dual 1-D heatmaps）表示关键点，无缝集成了坐标分类，达到与顶部-底部方法相当的精度，同时保持了较高的速度。我们设计了一种动态坐标分类器以及一种专门为热图学习设计的定制损失函数，专门解决了坐标分类与密集预测模型之间的不兼容问题。

**RTMO** 超越了现有的单阶段姿态估计器，在使用相同骨干网络的情况下，在 COCO 数据集上的平均精度（AP）提高了 1.1%，且运行速度快约 9 倍。我们最大的模型 **RTMO-l** 在 COCO val2017 数据集上达到了 74.8% 的 AP，并在单张 V100 GPU 上实现了 141 帧每秒（FPS）的速度，展现了其高效性和准确性。代码和模型可在以下地址获取：
 https://github.com/openmmlab/mmpose/tree/main/projects/rtmo