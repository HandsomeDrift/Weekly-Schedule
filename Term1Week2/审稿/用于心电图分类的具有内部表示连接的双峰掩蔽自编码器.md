# 用于心电图分类的具有内部表示连接的双峰掩蔽自编码器

## 摘要

时间序列的自监督方法被广泛应用，心电图（ECG）分类任务也从中受益。一个主流的范式是掩码数据建模（masked data modeling），该方法利用可见的数据部分来重建被掩码的部分，从而帮助获得对下游任务有用的表示。然而，传统方法主要关注时间域信息，并对编码器在重建方面提出过高要求，进而削弱了模型的判别能力。本文提出了一种用于心电图分类的**双模态掩码自动编码器与内部表示连接**（BMIRC）。一方面，BMIRC在掩码预训练过程中融合了ECG的频谱信息，增强了模型对心电图的全面理解；另一方面，它从编码器到解码器建立了**内部表示连接**（IRC），为解码器提供了多层次的信息以帮助重建，从而让编码器可以专注于建模判别性表示。我们在三个不同的ECG数据集上进行了全面实验，以验证BMIRC的有效性。实验结果表明，无论是在同域（在同一数据集上进行预训练和微调）还是跨域（在不同数据集上进行预训练和微调）设置中，BMIRC在大多数场景中均超越了竞争性基线方法。代码已公开，地址为：https://github.com/Envy-Clouds/BMIRC。

关键词：心电图；频谱；双模态；掩码自动编码器；内部表示连接

## 概述

作为一种非侵入性诊断程序，ECG是检测心律失常最方便和最有效的工具[1]。最初，ECG分析仅由人类专家执行，这种做法容易受到主观性和不同专业水平的影响，电脑科技的进步，大大提高了心电图的效率和准确性，基于辅助诊断方法，在医学界获得越来越多的关注[2，3]。


近年来，由于采用了深度学习方法，ECG分类任务取得了显着进步。研究人员已经通过利用卷积神经网络（CNN），变压器或其合并展示了令人满意的结果，表明此类方法在该领域的有效性[4，5]。


值得注意的是，这些方法主要在监督学习的框架内运行，需要大量的标记数据进行训练。此外，这种训练范式限制了未标记和外生数据源的利用。


在与深度学习相关的其他领域，如计算机视觉（CV）和自然语言处理（NLP），研究人员采用自监督学习来解决上述挑战[6，7]。这种范式利用辅助任务从未标记的数据中提取监督信息，使网络能够获得有利于后续任务的表示。一个用自我监督预处理增强的模型，training从未标记的数据中学习额外的知识，从而与仅通过监督训练训练的模型相比，在监督训练之后实现上级性能。值得注意的是，这些额外的知识可以应用于其他数据集以产生进一步的改进。

最近，用于时间序列分析的自监督方法已经变得流行，ECG分类任务也从这些进步中获益[8-14]。

掩蔽数据建模是该领域的主流范式。与依赖于预定一致性假设的对比学习不同，掩蔽数据建模关注数据的固有特征。这一特征增强了其适用性，从而促使我们将其应用于ECG分类任务。

然而，这些方法大多只关注时域信息，忽略了来自其他模态或视角的信息，考虑到多模态数据之间的互补性[15]，仅依赖于单一模态的方法无法捕捉到更全面的信息，从而限制了模型的推理和判断能力。

在掩模数据建模的框架内，当重建目标是原始数据时，最具代表性的范例是掩模自编码器（MAE）。它包括负责编码可见数据的编码器和负责重建掩模数据的解码器。在ECG分类任务中，许多心律类别与形态特征相关联。例如，心房颤动（AF）的典型特征是P波的缺失。2 MAE致力于挖掘原始数据的潜在特征，帮助模型学习这些有区别的细节。3这种动力驱使我们利用这种范式来推进我们的研究。

然而，由于自监督重建任务和监督下游任务之间存在差距，MAE的应用面临一些问题。根据信息瓶颈理论[16]，在典型的监督学习范式下，靠近输入的层捕获更多的低级信息，而靠近输出的层包含更多的高级信息。与上述范式不同，MAE编码器的浅层和MAE解码器的深层都包含丰富的低级信息。此外，各种级别的信息被保存在网络的中间层中，高级信息通常在编码器的深层中找到[17]。低级信息属于常见的形态细节，它与原始数据密切相关。高级信息属于判别表示，这对于下游分类任务至关重要。解码器依赖于编码器的最终输出将高级表示转换为低级表示。

然而，这样的解码过程迫使编码器过度集中于较低级别的信息，旨在帮助解码器更容易地完成重建。简而言之，这种配置导致编码器过度关注重建，从而限制了其学习高级区分表示的能力。

为了解决上述问题，我们提出了一种新的双峰掩蔽自编码器框架，表示为BMIRC。具体来说，我们采用离散傅立叶变换（DFT）将ECG转换为频谱，并将其视为一个独立的模态，这有助于补充模型用于学习的数据源。在频域分析已被广泛应用的先前研究中，这些方法通常涉及直接提取频域特征，随后将其输入到网络中[18]，或者采用双编码器在时域和频域中进行对比表示学习[9]我们利用频谱的方法涉及构建一个双峰联合编码器，旨在学习ECG和频谱的联合表示。进行屏蔽数据重构，ECG和频谱相互补充，促进可转移表示的学习。基于MAE范式，我们追求获得更多区分性表示涉及到各级信息的重用。具体来说，从编码器的中间层提取的表示被集成到解码器的各个层中，设计了一种门控表示混合器（GRM）来促进融合。我们将这个过程称为内部表示连接（IRC）。这种方法为解码器提供了各种级别的信息来帮助重建，减轻了解码器的负担，同时鼓励编码器获得更具鉴别力的表示。我们的主要贡献总结如下：

- 我们提出了一种新颖的用于时频联合建模的双模掩蔽自编码器框架。该方法将心电图的频谱集成到掩蔽预训练过程中，使双模联合编码器能够学习全面且通用的表示
- 我们在编码器和解码器之间建立内部表示连接（IRC），并设计了一个门控表示混合器（GRM）来复用不同层次的信息，从而减轻了解码器的重构负担，同时促进编码器获得更具鉴别力的表示。
- 通过在三个不同的ECG数据集上进行的综合实验，BMIRC在大多数情况下表现出优于竞争基线的上级性能，证明了所提出方法的有效性。

本文的后续部分结构如下：第2节介绍了多模态自监督学习和时间序列自监督学习的相关工作;第3节详细描述了所提出的BMIRC;第4节描述了实验设计;第5节评估了所提出方法的性能;第6节概括了本文的结论并描述了未来工作的方向。

## 相关工作

### 多模态自监督学习

在单模态研究领域，自监督学习方法取得了显著的进步。因此，当代研究越来越多地将注意力转向多模态领域。当然，值得注意的是，在该领域中，最近的努力的主要部分集中在图像和文本模态的集成上。现有的方法可以大致分为两类。第一类方法集中于通过基于变换器的多模态编码器对不同模态之间的交互进行建模。例如，在视觉和语言Transformer（ViLT）[19]和Align before transformer（ALBEF）[20]中，来自不同模态的表示用作联合编码器的输入。通过这种融合过程，联合编码器在不同的预训练任务中进行训练，第二类方法强调为单个模态训练专用编码器。例如，对比度图像预训练（CLIP）[21]利用对比度损失对编码器施加约束，促进跨不同模态的一致表示的获取。

虽然这些方法改进了图像和文本模态的表示学习，但对于具有独特属性和有限数据的时间序列，它们可能不太有效。

在心电图分析的背景下，从其他模态同时收集的数据的稀缺性对多模态自监督方法的适用性构成了限制。此外，为图像和文本模态设计的预训练任务的有效性在应用于心电图和其他相关模态时仍然不确定。

因此，我们致力于从原始ECG的不同角度探索数据源，并设计基于屏蔽数据建模的双峰自监督方法，这提供了更强的适用性。

## 时间序列的自监督学习

时间序列自监督学习方法的日益流行主要是由于CV和NLP的实质性进展。

一种范式是基于对比学习，其重点是通过施加不变性约束来进行表征学习。例如，时频一致性（TF-C）[9]假定时频域内的一致性，并通过减少相同样本的时频域表示之间的差异来进行预训练。对比预测编码（CPC）[12]和时频一致性（T-C）[14]通过时间和上下文对比的系列表示学习框架（TS-TCC）[8]主要强调时间不变性。CPC通过预测后续时间步的表示来实现它，而TS-TCC则致力于最大化跨不同视图的相同时间跨度的表示之间的相似性。通用时间序列表示学习（TimesURL）[22]首先引入了一种基于频率-时间的增强来保持时间属性。值得注意的是，时间重建作为一个联合优化目标与对比学习相结合，以捕获片段级别和实例级别的信息。然而，必须承认，无论是不同的增强策略还是不变性假设都不适用于所有场景。

另一种范式依赖于屏蔽数据建模，利用自编码器在可见数据的基础上重构屏蔽数据，其代表作是Patch Time Series Transformer（PatchTST）[10]和时间序列掩蔽自动编码器（TimeMAE）[11]，共享一个共同的特性，因为它们都将时间序列划分为非重叠的补丁，PatchTST遵循MAE范式，旨在重建原始时间序列。相比之下，TimeMAE致力于特征级重建。


此外，有一种方法认为，随机掩蔽某些时间点的标准方法可能会严重破坏时间序列中重要的时间变化。用于掩蔽时间序列建模的简单预训练框架（SimMTM）[23]通过加权聚合流形外的多个邻居来恢复被屏蔽的时间点。这些方法不依赖于人为预定的假设，因此更适合在新领域应用。


受此鼓舞，我们采用屏蔽数据建模的范式来制定我们的模型。


在ECG表示学习领域，CPC在获取广义表示方面表现出有效性[13]。基于MAE范式的几种变体被提出来在时间和变量的双重维度中执行掩蔽数据建模[14]。然而，这些方法目前仅限于直接应用和对其他领域现有方法的简单改进，在屏蔽数据建模的基础上，引入心电图的频谱特征进行双峰学习，并通过内部表示连接（IRC）鼓励编码器学习更多有区别的表示，以获得更全面、更有区别的表示，从而提高下游分类任务的性能。

## 方法

以下部分详细描述了我们提出的方法。


1，我们的方法包括预训练和微调阶段。由于数据集只提供原始ECG，首先生成ECG和频谱的补丁嵌入，表示为时频补丁嵌入。在预训练阶段，时频补丁嵌入在掩蔽之后被馈送到双峰联合编码器。然后，该算法采用模态相关解码器，在IRC的帮助下重建被屏蔽的数据，该阶段不需要任何标签的参与，在微调阶段，解码器由分类器代替，分类器由全局平均池层和线性层组成.


剩余的网络使用预训练的模型参数进行初始化。这个阶段需要进行常规的监督训练。更多细节如图2所示。接下来，我们将介绍上述步骤的每个组成部分。

### 时频贴片嵌入

正如图2所述，一个心电图（ECG）的第i导联，表示为 $ t_i \in \mathbb{R}^L $，通过离散傅里叶变换（DFT）被转换为频谱 $ f_j \in \mathbb{R}^N $：

$$
f_j(k) = \text{DFT}[t_i] = \sum_{n=0}^{N-1} t_i(n) \cdot e^{-j \frac{2\pi}{N}kn}, k = 0, 1, \dots, N-1
$$
其中，$ n $ 是时间点的索引，$ k $ 表示ECG中存在的不同频率。根据频域采样定理，DFT变换的区间 $ N $ 必须大于或等于ECG的长度 $ L $，以防止混叠。在这种情况下，我们设定 $ N = L $ 来得到 $ f_j \in \mathbb{R}^L $。这一过程可以通过快速傅里叶变换（FFT）算法有效计算。

由于在变换后的频谱中存在对称性，我们截取了 $ f_j $ 的前半部分 $ f_j^* \in \mathbb{R}^{\frac{L}{2}} $，以减少冗余。频谱揭示了数据中存在的各种频率成分的比例，从而从另一个角度揭示数据的特性。各种类型的ECG在时间域中展现出不同的形态特征。例如，房颤（AF）的典型特征是P波的缺失，而左束支阻滞（LBBB）和右束支阻滞（RBBB）则通过QRS波形的改变来区分。ECG中存在的变化也反映在频谱中。这一事实直观地支持了整合频域信息来增强模型判别能力的合理性。

在大多数方法以逐点方式处理时间序列数据的背景下，基于patch的建模方法已被证明是有效的。特别是，推断被掩码的区域比推断被掩码的点更具挑战性。因此，基于patch的重建任务鼓励预训练模型学习更多潜在信息。在我们的方法中，ECG和频谱被分成不重叠的patch以进行编码。一个多导联ECG及其对应的频谱表示为 $ T = [t_1, t_2, \dots, t_C] \in \mathbb{R}^{L \times C} $ 和 $ F = [f_1^*, f_2^*, \dots, f_C^*] \in \mathbb{R}^{\frac{L}{2} \times C} $，其中 $ C $ 是导联的数量。我们使用两个一维卷积层对来自两种模态的patch进行编码。卷积核的大小设为 $ S \times C $，步长设为 $ S $，以确保patch的独立性。在这种配置下，每个patch的长度为 $ S $，表示心电图的一个片段。按照MAE的思想，patch嵌入被表示为token，每个token对应于特定patch的嵌入。T和F的token表示为：

$$
Z_t = [z_t^1, z_t^2, \dots, z_t^{\frac{L}{S}}] \in \mathbb{R}^{\frac{L}{S} \times D}, Z_f = [z_f^1, z_f^2, \dots, z_f^{\frac{L}{2S}}] \in \mathbb{R}^{\frac{L}{2S} \times D}
$$
其中，$ D $ 表示卷积核的数量，表示每个token的维度。"t"和"f"分别表示ECG和频谱模态。为了便于表述，ECG和频谱也分别被称为时间和频率模态。在接下来的部分中，使用了 $ N_t = \frac{L}{S} $ 和 $ N_f = \frac{L}{2S} $ 来表示时间和频率模态中的token数量。

### 双模联合编码器



## 实验设计

### 数据集和指标

为了评估我们模型的有效性，我们在三个公开的数据集上进行了实验：宁波数据集[25]（来自宁波第一医院），PTBXL数据集[26]（来自Physikalisch-Technische Bundesanstalt）和Chapman数据集[27]（来自查普曼大学，绍兴市人民医院）。这些数据集包括12导联ECG，分别包含34，905，21，837和10，247个临床记录，每个跨度为10秒。我们从心脏病学计算挑战（CinC）2021数据库[28]中获得上述数据集的原始数据，所有数据都以500 Hz的统一采样率记录。在CinC 2021数据库中，每个ECG记录都有一个或多个标签，表示各种心律类别，并映射到SNOMED-CT代码。这意味着所有后续实验都执行多标签分类任务。此外，还使用了另外两个公共心电图多标签数据集：格鲁吉亚[28]和合肥[29]来进一步验证我们的模型对下游任务的泛化能力。这两个数据集包含10，344和20，335个样本，采样率为500 Hz，每个样本的持续时间为10秒。

在后续的实验中，引入了准确率（ACC）、样本F1得分（F1）、受试者工作特征曲线下面积（AUROC）和精确召回曲线下面积（AUPRC）作为分类性能的评价指标。

### 数据预处理

所用数据集的预处理包括几个基本步骤：

1. **去噪：**噪声、基线漂移和运动伪影等干扰因素通常会在原始ECG中出现[30]，从而对模型的分类性能产生负面影响，为了减轻上述因素的影响，采用截止频率为0.05和75 Hz的巴特沃思带通滤波器[31]来提取最基本的信息。
2. **下采样：**所有ECG记录都经过降采样至100 Hz以降低计算成本。在该领域的先前研究中记录了类似的降采样程序[14，32]。
3. **规范化：**实例归一化[33]应用于每个ECG记录的每个导联，这可以帮助减轻分布偏移效应[10]。
4. **标签重建：**将分配给每个样本的SNOMED-CT编码转换为离散的类别编码，得到宁波、PTB-XL和Chapman数据集，宁波、PTB-XL和Chapman数据集分别为25、22和19类，格鲁吉亚和合肥数据集分别为23和34类，这些数据集表现出类别不平衡性，其特点是在个别类别中阳性和阴性样本的数量存在显著差异，不同类别的样本数量也存在显著差异。
5. **数据集分区：**我们利用分层采样将20%的数据集划分为测试集，而剩余部分则分配用于预训练和微调阶段的训练。

### 比较方法

我们将我们的方法与几个流行的基线进行了比较。

1. TF-C [9]在三个不同的域上执行对比学习：时域、频域和时频域，以获得可转移的表示。
2. TS-TCC [8]通过跨视图预测来学习鲁棒的时间表示，并在不同视图之间执行对比学习以增强模型的可辨别性。
3. CPC [13]通过利用当前时间步长的上下文表征来预测后续时间步长的表征，从而关注时间不变性。
4. TimesURL [22]引入了基于频率-时间的增强以保持时间属性，同时将时间重构作为联合优化目标与对比学习相结合。
5. SimMTM [23]集成了用于掩模重建的流形学习，通过流形外的多个相邻点的加权聚合来恢复被掩蔽的时间点。
6. PatchTST [10]将时间序列划分为斑块，并在预训练阶段使用掩蔽数据重建任务。
7. TimeMAE [11]对时间序列采用了窗口切片策略，并集成了两个不同的任务：掩蔽表示回归和掩蔽码字分类，从而促进了表示学习。

对于TF-C和TS-TCC，InceptionTime [34]或ResNet 1d wang [35]被用作编码器，这两种都是时间序列分类中常用的基线，特别是在ECG分类中。对于SimMTM，除了默认编码器外，我们还使用ResNet 1d wang进行比较。对于其他基线，我们使用相应论文建议的编码器，这是根据各自的算法量身定制的。为了评估我们的方法中预训练的有效性，随机初始化被引入作为比较方法。随机初始化是我们模型的一个版本，没有预训练的权重。也就是说，它在微调阶段从头开始进行监督训练。

### 实现细节

在我们的方法中，卷积核大小设置为10 × 12，其中12表示ECG导联的数量，每个补丁通过1D卷积层被编码为192维嵌入。模态特定编码器和共享编码器中的Transformer块的数量被设置为4。特定的解码器包括4个Transformer块，输入维度设置为96。所有Transformer块的注意头的数量统一设置为3。ECG及其频谱的掩蔽率分别设置为50%和75%。重建损失权重α和β，时间和频率模态的设置为1.0。数据采样率设置为100 Hz。有关参数分析的更多详细信息，请参见第5.5节。


预训练阶段包括300个epoch，微调阶段包括30个epoch。两个阶段的批量大小都是128。我们使用AdmW作为优化器，权重衰减为0.05。此外，余弦退火衰减和预热策略用于优化学习过程。在预训练阶段，学习率为0.0001，预热期为40。在微调阶段，学习率为0.001，预热期为5。对于上述基线，大多数训练超参数来自相应的论文。

由于标签内部固有的类别不平衡性，我们在微调阶段采用了类别加权策略，以获得更合理的结果。所有实验均在单个RTX 2080-Ti GPU上进行。

## 实验结果

实验在两个域内进行（在同一数据集上进行预训练和微调）和跨域表中的TF-C和TS-TCC的下标“I”或“R”分别表示编码器变体InceptionTime或ResNet 1d wang。表中的SimMTM的下标“D”或“R”表示其默认编码器或ResNet 1d wang。分别

最佳结果以粗体突出显示，次佳结果以下划线突出显示。所有度量均以百分比（%）表示。

![image-20240916183334642](%E7%94%A8%E4%BA%8E%E5%BF%83%E7%94%B5%E5%9B%BE%E5%88%86%E7%B1%BB%E7%9A%84%E5%85%B7%E6%9C%89%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%8C%E5%B3%B0%E6%8E%A9%E8%94%BD%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.assets/image-20240916183334642.png)

### 域内评估

在本节中，所有实验都是在同一数据集上进行的，以评估模型的域内泛化能力。最初，模型在不使用标签的情况下进行自我监督的预训练。随后，在微调阶段加入标签以改进模型。在这个两阶段训练协议之后，在测试集上评估模型的性能。表1示出了我们的方法相对于基线的分类结果。广义地说，我们的BMIRC在Ningbo和PTB-XL数据集上与所有基线相比表现出上级性能，但在Chapman数据集上表现出稍差的性能。随着数据集大小的扩大，与基线相比，我们的BMIRC的性能增强也显示出逐渐增加。例如，在PTB-XL数据集上，与次优模型CPC相比，BMIRC实现了1.4%的改进。同样，在宁波数据集上，与次优模型CPC相比，虽然BMIRC在Chapman数据集上的整体性能福尔斯低于TS-TCCR，但我们认为这种情况可以通过迁移学习来改变（细节在下一节中提供）。与不利用预训练权重的Random Init相比，我们的BMIRC表现出显著的优势，在所有数据集中，大多数指标的改进超过3%。值得注意的是，虽然基于对比度的基线通常优于基于掩模的基线，但它们并没有超过我们的BMIRC。我们将这一现象归因于我们方法中频率模态的引入和对传统MAE架构的增强。

![image-20240916183528355](%E7%94%A8%E4%BA%8E%E5%BF%83%E7%94%B5%E5%9B%BE%E5%88%86%E7%B1%BB%E7%9A%84%E5%85%B7%E6%9C%89%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%8C%E5%B3%B0%E6%8E%A9%E8%94%BD%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.assets/image-20240916183528355.png)

### 跨域评估

为了评估模型在跨域设置下的性能，在对较小数据集进行监督学习之前，使用在较大数据集上进行预训练得到的权重来初始化模型。这个过程代表了迁移学习中遇到的典型场景，用于验证预训练权重的可迁移性。我们在三种场景下进行实验：Ningbo→PTB-XL、Ningbo→Chapman和PTB-XL→Chapman，确保从较大数据集获得的预训练权重应用于较小数据集。表2显示了跨域设置的评估结果。在大多数场景中，我们的BMIRC超过基线。对于Chapman数据集，采用来自较大数据集的预训练权重显著增强了大多数模型的性能，如表1中的Chapman结果与表2中的Ningbo→Chapman，PTB-XL→Chapman结果之间的比较所证明的。此外，观察到在我们的方法中，更大的预训练数据集对应着更显著的改进。例如，我们的BMIRC的AUPRC在PTB-XL→Chapman场景中增加了4%，在Ningbo→Chapman场景中增加了12.7%，这一发现表明，我们的BMIRC可以提高其泛化能力，通过在大型数据集上进行广泛的预训练，

## 使用更多下游数据集进行微调

为了进一步验证我们的模型在更多下游任务上的泛化能力（跨域微调），我们的BMIRC在格鲁吉亚和合肥数据集上与Random Init和TS-TCCR进行了比较。除了基于Ningbo数据集的预训练权重外，还使用了Ningbo，PTB-XL和Chapman数据集，以获得更强大的预训练权重。如表3所示，我们的BMIRC在这些下游任务上的表现优于基线，更大的预训练数据集与更高的性能相关。

### 不同比例训练集的微调

预训练模型已被证明具有增强的泛化能力，特别是在具有稀疏标签的场景中[36]。在本节中，我们评估不同比例的训练集的效果（25%，50%，75%，100%）对模型性能的影响。如表4所示，我们给出了两种不同场景的分类结果：宁波（域内）和宁波→查普曼（跨域）。总体而言，我们的BMIRC在大多数情况下优于所有基线，仅在使用25%的宁波数据集时表现出劣于TS-TCCR。这一观察结果与Chapman数据集获得的评估结果一致。值得注意的是，随着标记数据量的增加或在跨域设置内，BMIRC的表现一直优于TS-TCCR。我们注意到，随着训练集比例的增加，基线的性能逐渐改善，但改善的幅度逐渐减缓。我们的BMIRC在进行域内微调时表现出类似的趋势。但是，在跨域设置下，它只需使用75%的训练集就可以实现近似最佳的性能。此外，在两种不同的场景中，我们的BMIRC的性能（仅在50%的训练集上训练），超过了在整个数据集上训练的Random Init。这个特性有助于我们的BMIRC在下游任务标签稀疏时获得令人满意的结果。

![image-20240916183658443](%E7%94%A8%E4%BA%8E%E5%BF%83%E7%94%B5%E5%9B%BE%E5%88%86%E7%B1%BB%E7%9A%84%E5%85%B7%E6%9C%89%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%8C%E5%B3%B0%E6%8E%A9%E8%94%BD%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.assets/image-20240916183658443.png)

### 模型主要参数分析

在这一部分中，我们分析了Ningbo（域内）和Ningbo-Chapman（跨域）两种不同场景下模型的主要参数，包括双峰掩模率、双峰重建损失权重和ECG采样率

#### 双峰掩蔽率分析

![image-20240916183735148](%E7%94%A8%E4%BA%8E%E5%BF%83%E7%94%B5%E5%9B%BE%E5%88%86%E7%B1%BB%E7%9A%84%E5%85%B7%E6%9C%89%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%8C%E5%B3%B0%E6%8E%A9%E8%94%BD%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.assets/image-20240916183735148.png)

时间和频率模态的独特特征，以及它们在双峰联合表示中占据的信息比例的差异，决定了两种模态的不同掩蔽率组合会影响模型的表示学习。我们研究了不同掩蔽率组合对模型性能的影响，并报告了ACC和AUPRC。如图5所示，我们注意到一个一致的趋势，频率模态掩蔽率的增加对应于模型性能的逐渐改善。这一观察结果由所有子图的每列内从底部到顶部的进展证明。保持频率模态中的掩蔽率恒定，经常观察到模型性能在时间模态中的50%的掩蔽率处达到其峰值。最终，最佳配置被确定为时间模态掩蔽率为50%，频率模态掩蔽率为75%。我们将这一观察结果归因于时间模态固有的复杂性，因此，过高的时间模态掩蔽率对模型有效地从时间模态中提取潜在模式提出了挑战。

![image-20240916183804624](%E7%94%A8%E4%BA%8E%E5%BF%83%E7%94%B5%E5%9B%BE%E5%88%86%E7%B1%BB%E7%9A%84%E5%85%B7%E6%9C%89%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%8C%E5%B3%B0%E6%8E%A9%E8%94%BD%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.assets/image-20240916183804624.png)

考虑到一些基于掩蔽的自监督方法的最佳掩蔽率为60% [11]，我们进一步探索更多样的掩蔽率组合。具体地说，基于最佳组合（50%和75%），我们设置了三个额外的组合：50%的时间模态和60%的频率模态（T M = 50%，FM = 60%）;时间模态为60%，频率模态为75%（T M = 95%，F M = 0.0 5%）;时间和频率模态均为60%如表5所示，引入60%的掩蔽率降低了在先前的最佳配置下模型的总体性能（T M = 50%，FM = 75%），表明60%的掩蔽率不适合我们的任务。

#### 双模态重构损失权分析

在双峰联合建模过程中，重建损失的权重可能会影响模型的性能。使用不同的权重组合进行预训练，最终的分类结果如表6所示。当α和β都设置为1.0时，模型的性能达到最佳，表明两种模态的重建损失权重同等重要。

![image-20240916183840906](%E7%94%A8%E4%BA%8E%E5%BF%83%E7%94%B5%E5%9B%BE%E5%88%86%E7%B1%BB%E7%9A%84%E5%85%B7%E6%9C%89%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%8C%E5%B3%B0%E6%8E%A9%E8%94%BD%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.assets/image-20240916183840906.png)

#### 心电图采样率的分析

为了验证不同输入长度对模型性能的影响，我们使用采样率为50 Hz、100 Hz和200 Hz的ECG进行实验，分别代表输入长度为500、1000和2000。如表7所示，随着输入长度从500增加到1000，模型性能提高，但输入长度越大，2000的性能越差。2这表明过多的数据冗余对模型学习是不利的。

### 消融实验

在本节中，我们在BMIRC上进行消融实验。首先，我们研究了丢弃频率模态对模型性能的影响。该模型变体表示为w/o频率，完整模型表示为Full Model。


其次，我们比较了两种不同的模型架构，如图3所示：一个单独利用共享编码器，表示为All Shared，另一个采用我们的双模联合编码器，包括模态特定编码器和共享编码器，表示为Specific-Shared。在w/o频率和All Shared的情况下，我们增加时间编码器层和共享编码器层的数量，最后，我们研究了IRC和GRM的效果。


所有的实验都在域内和跨域设置下跨六个场景进行。

#### 额外频率模态的影响

表8给出了在所有场景中，当主要成分缺失时的实验结果。正如我们所看到的，在所有场景中，当丢弃频率模态时，性能都显著下降。我们将此现象归因于频率模态可以为时间模态提供有价值的补充信息。丢弃频率模态缩小了模型提取区分性表征的能力，最终导致性能下降。

![image-20240916184624312](%E7%94%A8%E4%BA%8E%E5%BF%83%E7%94%B5%E5%9B%BE%E5%88%86%E7%B1%BB%E7%9A%84%E5%85%B7%E6%9C%89%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%8C%E5%B3%B0%E6%8E%A9%E8%94%BD%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.assets/image-20240916184624312.png)

#### 双模联合编码器的效果

如表9所示，我们的专用共享架构在大多数场景中优于全共享架构，仅在宁波→查普曼场景中表现略差。我们给出了两种架构在所有场景中的平均排名，以全面评估其整体性能。我们的专用共享架构在ACC、F1、和AUPRC指标，同时保持可比性，它的AUROC指标。在所有共享的架构，它把两个模态作为一个整体，我们的Specific-Shared架构的目的是明确地捕捉交互关系内和模态之间。实验结果强调了这种层次结构的意义，在我们的框架。

![image-20240916184632651](%E7%94%A8%E4%BA%8E%E5%BF%83%E7%94%B5%E5%9B%BE%E5%88%86%E7%B1%BB%E7%9A%84%E5%85%B7%E6%9C%89%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%8C%E5%B3%B0%E6%8E%A9%E8%94%BD%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.assets/image-20240916184632651.png)

#### IRC的影响

我们初步研究了丢弃IRC对模型性能的影响，对比表8中不带IRC和完整模型的分类结果，可以看出IRC的引入全面提高了模型的性能。

这一观察结果表明，向解码器提供各种级别的信息进行重构可以增强编码器学习高级判别表示的能力。我们进行了分析，重点是它的应用程序，以一个单一的模态和检查的影响，不同的IRC层的数量-定义为连接编码器和解码器的层数。为了便于解释，我们使用AUPRC进行后续分析，AUPRC因其对类不平衡下的模型性能的高度敏感性而被认可。

如图6（a）所示，AUPRC结果在四种不同的情况下呈现：1）无IRC：没有IRC，2）IRC（时间）：仅在时间模态上使用IRC，3）IRC（频率）：仅在频率模态上使用IRC，以及4）IRC（全部）：在时间和频率模态上使用IRC。

我们的研究结果表明，在大多数情况下，IRC的集成导致性能增强，从而突出了其有效性。在域内设置下，IRC（All）始终优于其竞争对手。尽管IRC（All）在跨域设置下没有达到最佳结果，但它接近最佳性能。因此，我们选择IRC（All）作为默认配置，因为它的性能更平衡。

![image-20240916184719234](%E7%94%A8%E4%BA%8E%E5%BF%83%E7%94%B5%E5%9B%BE%E5%88%86%E7%B1%BB%E7%9A%84%E5%85%B7%E6%9C%89%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%8C%E5%B3%B0%E6%8E%A9%E8%94%BD%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.assets/image-20240916184719234.png)

假设解码器深度为4，我们从解码器的第二层开始递增IRC层的数量，表示为F1、F2和F3，其中F3表示完整模型。如图6（B）所示，呈现了对应于三种情况的AUPRC结果。正如我们所看到的，F3在大多数情况下实现了最佳性能，仅在PTB-XL→Chapman场景中表现不佳。F2具有最差的整体性能，我们将其归因于涉及从双峰共享表示到单峰唯一表示的切换的第二层融合。


更多单峰表示的融合（如F3）有助于模型适应这一过程，从而提高整体性能。

#### GRM的影响

表10显示了图4所示的三种融合方法在所有场景中的分类结果。在域内设置下，与竞争对手相比，我们的GRM表现出上级的整体性能。然而，在跨域设置下，似乎没有明显的赢家。三种融合方法在所有场景中的平均排名见表10，这表明GRM独特的自适应选通融合策略可以增强模型的泛化能力。

### 可视化分析

为了增强对所提出的方法的理解，进行了可视化分析，主要强调IRC对重建任务的影响。中心核对齐（CKA）相似性[37]用于评估模型中每个层的表示与输入数据之间的相关性。我们提出了三种情况下的CKA相似性：1）随机初始化，2）没有IRC的预训练，以及3）我们的完整模型。如图7所示，蓝色区域对应于编码器表示，而绿色区域对应于解码器表示。直观地说，解码级中较高的CKA相似性表示模型的上级重构性能，因为这意味着模型捕获更多与输入数据相关的信息。

![image-20240916184826882](%E7%94%A8%E4%BA%8E%E5%BF%83%E7%94%B5%E5%9B%BE%E5%88%86%E7%B1%BB%E7%9A%84%E5%85%B7%E6%9C%89%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%8C%E5%B3%B0%E6%8E%A9%E8%94%BD%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.assets/image-20240916184826882.png)

随机初始化作为一个参考点来证明，在没有重建损失约束的情况下，模型表示和输入数据之间的CKA相似性将逐渐减少。对于时间模态，我们的完整模型与输入数据相比，与w/o IRC相比，表现出更高的亲和力，这可以通过解码阶段更高的CKA相似性来证明。此外，在解码器内存在逐层观察到的增加相似性的可辨别的趋势。该观察结果表明IRC的引入确实增强了重构过程并减轻了解码器的负担。对于频率模态，我们没有观察到IRC对重建有积极影响。我们将这种现象归因于频率模态复杂度低并且重建相对简单，从而降低了IRC对重建的功效。此外，频率解码器的表示与输入数据之间的CKA相似性在三个数据集上保持相对稳定。一个可能的解释是，模型的解码能力存在上限，而频率模态固有的低复杂度使得模型很容易接近这个上限，IRC的引入虽然没有超过这个上限，但仍然减轻了解码器的负担，避免了对编码器的过度重构要求。

![image-20240916184858299](%E7%94%A8%E4%BA%8E%E5%BF%83%E7%94%B5%E5%9B%BE%E5%88%86%E7%B1%BB%E7%9A%84%E5%85%B7%E6%9C%89%E5%86%85%E9%83%A8%E8%A1%A8%E7%A4%BA%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%8C%E5%B3%B0%E6%8E%A9%E8%94%BD%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.assets/image-20240916184858299.png)

如图8所示，我们展示了IRC对实际重建性能的影响。对于时间模态，与w/o IRC相比，与IRC集成的模型表现出对细节的更大关注，特别是与黑色圆圈突出显示的区域相比。这证明了IRC的引入确实提高了时间模态的重建性能。对于频率模态，两个版本的重建性能仍然相当。这些发现与之前对CKA的分析一致，并为IRC的有效性提供了更直观的证明。

## 结论

本文提出了一种新的用于心电图分类的双峰掩蔽自编码器框架BMIRC。BMIRC的一个特点是将心电图产生的频谱作为一个独立的模态纳入掩蔽预训练过程。所提出的双峰联合编码器捕获从模态内到模态间的相互作用，从而获得更全面的表示。此外，我们建立了从编码器到解码器的内部表示连接（IRC），并设计了一个门控表示混合器（GRM）来执行融合过程。这些增强减轻了解码器的负担，从而增强编码器学习判别表示的能力。我们在域内和跨域内进行了多组实验，在三个公开的ECG数据集上进行了实验，结果证明了BMIRC的有效性，并进一步证明了预训练的ECG权值的可移植性

然而，我们模型内部特征的可解释性仍然是一个挑战，这也是基于深度学习方法的痛点。在医疗领域的实际应用中，模型决策过程的可解释性对于临床医生来说尤为重要。未来，我们将致力于开发新的方法来提高BMIRC的可解释性，在模型的内部细节方面，我们计划进一步探索和优化跨模态信息融合技术，以减少不同模态之间的不一致性和噪声，从而提高模型的稳定性和鲁棒性。
